<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>llmaz core API | llmaz</title>
<meta name=description content="Generated API reference documentation for llmaz.io/v1alpha1."><meta property="og:url" content="https://llmaz.inftyai.com/docs/reference/core.v1alpha1/"><meta property="og:site_name" content="llmaz"><meta property="og:title" content="llmaz core API"><meta property="og:description" content="Generated API reference documentation for llmaz.io/v1alpha1."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2025-06-10T16:31:52+08:00"><meta itemprop=name content="llmaz core API"><meta itemprop=description content="Generated API reference documentation for llmaz.io/v1alpha1."><meta itemprop=dateModified content="2025-06-10T16:31:52+08:00"><meta itemprop=wordCount content="700"><meta name=twitter:card content="summary"><meta name=twitter:title content="llmaz core API"><meta name=twitter:description content="Generated API reference documentation for llmaz.io/v1alpha1."><link rel=preload href=/scss/main.min.df756438a7e020f7456327e32660cfd018c35e49c250d72b637e5a0fdc7f595c.css as=style integrity="sha256-33VkOKfgIPdFYyfjJmDP0BjDXknCUNcrY35aD9x/WVw=" crossorigin=anonymous><link href=/scss/main.min.df756438a7e020f7456327e32660cfd018c35e49c250d72b637e5a0fdc7f595c.css rel=stylesheet integrity="sha256-33VkOKfgIPdFYyfjJmDP0BjDXknCUNcrY35aD9x/WVw=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-page><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg version="1.2" viewBox="0 0 29 30" width="29" height="30"><style>.a{fill:#fff;stroke:#e94751;stroke-linecap:round;stroke-linejoin:round;stroke-width:.4}</style><path class="a" d="m14.3.0-13.7 6.5c-.2.0-.2.3.0.4L3 8.1q.2.1.4.0l11-5.5q.2.0.3.0l1.9.9c.3.2.2.3.0.4L6 9.3c-.2.1-.2.3.0.4L8.5 11q.1.1.3.0l10.8-6q.1.0.2.0l2.5 1.2c.2.0.2.3.0.4l-10.1 5.5c-.4.1-.6.5-.2.8l2.3 1.2c.2.1.4.0.5.0L28.2 7c.4-.2.4-.7.0-.9L14.7.0q-.2.0-.4.0z"/><path class="a" d="m29 8.8v3.3l-.1.1-9.3 12.5 9.1-4.9c.1.0.3.0.3.2v3l-13.2 7c-.2.1-.6-.1-.6-.4v-3.5q0-.1.1-.1l9.3-12.2s0-.1-.1.0l-9 5.4c-.1.1-.3.0-.3-.2v-3c0-.3.2-.5.4-.6l12.9-6.9c.2-.1.5.0.5.3z"/><path class="a" d="m13.6 15.4-12.9-6.6c-.3-.2-.7.1-.7.4v13.3q0 .1.1.2l2.1 1c.2.1.5-.1.5-.4v-3.2l7.5 3.8v4.3q0 .2.2.3l2.7 1.5c.3.1.7-.1.7-.5V15.9c0-.2-.1-.4-.2-.5zM2.7 17.3v-3.4c0-.1.2-.2.3-.1l7 3.4c.1.1.2.3.2.5V21z"/></svg></span><span class=navbar-brand__name>llmaz</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class="nav-link active" href=/docs/><span>Documentation</span></a></li><li class=nav-item><a class="nav-link active" href=/docs/reference/><span>Reference</span></a></li><li class=nav-item><a class=nav-link href=/blog/><span>Blog</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><ul class=dropdown-menu><li><a class=dropdown-item href=/docs>latest</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.fba1acde53f3296508caf74156f83068.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><div id=content-mobile><form class="td-sidebar__search d-flex align-items-center"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.fba1acde53f3296508caf74156f83068.json data-offline-search-base-href=/ data-offline-search-max-results=10></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form></div><div id=content-desktop></div><nav class="td-sidebar-nav collapse td-sidebar-nav--search-disabled" id=td-section-nav><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-docs-li><a href=/docs/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-docs><span>Documentation</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-docsgetting-started-li><a href=/docs/getting-started/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsgetting-started><span>Getting Started</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsgetting-startedprerequisites-li><a href=/docs/getting-started/prerequisites/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedprerequisites><span>Prerequisites</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsgetting-startedinstallation-li><a href=/docs/getting-started/installation/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedinstallation><span>Installation</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsgetting-startedbasic-usage-li><a href=/docs/getting-started/basic-usage/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedbasic-usage><span>Basic Usage</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-docsintegrations-li><a href=/docs/integrations/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsintegrations><span>Integrations</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsintegrationsenvoy-ai-gateway-li><a href=/docs/integrations/envoy-ai-gateway/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsintegrationsenvoy-ai-gateway><span>Envoy AI Gateway</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsintegrationsopen-webui-li><a href=/docs/integrations/open-webui/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsintegrationsopen-webui><span>Open-WebUI</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsintegrationsprometheus-operator-li><a href=/docs/integrations/prometheus-operator/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsintegrationsprometheus-operator><span>Prometheus Operator</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsintegrationssupport-backends-li><a href=/docs/integrations/support-backends/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsintegrationssupport-backends><span>Supported Inference Backends</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsdevelop-li><a href=/docs/develop/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsdevelop><span>Develop Guidance</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-docsreference-li><a href=/docs/reference/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsreference><span>Reference</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-docsreferencecorev1alpha1-li><a href=/docs/reference/core.v1alpha1/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-docsreferencecorev1alpha1><span class=td-sidebar-nav-active-item>llmaz core API</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsreferenceinferencev1alpha1-li><a href=/docs/reference/inference.v1alpha1/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsreferenceinferencev1alpha1><span>llmaz inference API</span></a></li></ul></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"><a href=https://github.com/InftyAI/llmaz/tree/main/site/content/en/docs/reference/core.v1alpha1.md class="td-page-meta--view td-page-meta__view" target=_blank rel=noopener><i class="fa-solid fa-file-lines fa-fw"></i> View page source</a>
<a href=https://github.com/InftyAI/llmaz/edit/main/site/content/en/docs/reference/core.v1alpha1.md class="td-page-meta--edit td-page-meta__edit" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Edit this page</a>
<a href="https://github.com/InftyAI/llmaz/new/main/site/content/en/docs/reference?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class="td-page-meta--child td-page-meta__child" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Create child page</a>
<a href="https://github.com/InftyAI/llmaz/issues/new?title=llmaz%20core%20API" class="td-page-meta--issue td-page-meta__issue" target=_blank rel=noopener><i class="fa-solid fa-list-check fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/InftyAI/llmaz/issues/new class="td-page-meta--project td-page-meta__project-issue" target=_blank rel=noopener><i class="fa-solid fa-list-check fa-fw"></i> Create project issue</a>
<a id=print href=/docs/reference/_print/><i class="fa-solid fa-print fa-fw"></i> Print entire section</a></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#resource-types>Resource Types</a></li><li><a href=#llmaz-io-v1alpha1-OpenModel><code>OpenModel</code></a></li><li><a href=#llmaz-io-v1alpha1-Flavor><code>Flavor</code></a></li><li><a href=#llmaz-io-v1alpha1-FlavorName><code>FlavorName</code></a></li><li><a href=#llmaz-io-v1alpha1-InferenceConfig><code>InferenceConfig</code></a></li><li><a href=#llmaz-io-v1alpha1-ModelHub><code>ModelHub</code></a></li><li><a href=#llmaz-io-v1alpha1-ModelName><code>ModelName</code></a></li><li><a href=#llmaz-io-v1alpha1-ModelRef><code>ModelRef</code></a></li><li><a href=#llmaz-io-v1alpha1-ModelRole><code>ModelRole</code></a></li><li><a href=#llmaz-io-v1alpha1-ModelSource><code>ModelSource</code></a></li><li><a href=#llmaz-io-v1alpha1-ModelSpec><code>ModelSpec</code></a></li><li><a href=#llmaz-io-v1alpha1-ModelStatus><code>ModelStatus</code></a></li><li><a href=#llmaz-io-v1alpha1-URIProtocol><code>URIProtocol</code></a></li></ul></nav></div><div class="taxonomy taxonomy-terms-cloud taxo-categories"><h5 class=taxonomy-title>Categories</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://llmaz.inftyai.com/categories/inference/ data-taxonomy-term=inference><span class=taxonomy-label>Inference</span><span class=taxonomy-count>1</span></a></li></ul></div><div class="taxonomy taxonomy-terms-cloud taxo-tags"><h5 class=taxonomy-title>Tags</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://llmaz.inftyai.com/tags/release-note/ data-taxonomy-term=release-note><span class=taxonomy-label>Release-Note</span><span class=taxonomy-count>1</span></a></li></ul></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><nav aria-label=breadcrumb class=td-breadcrumbs><ol class=breadcrumb><li class=breadcrumb-item><a href=/docs/>Documentation</a></li><li class=breadcrumb-item><a href=/docs/reference/>Reference</a></li><li class="breadcrumb-item active" aria-current=page>llmaz core API</li></ol></nav><div class=td-content><h1>llmaz core API</h1><div class=lead>Generated API reference documentation for llmaz.io/v1alpha1.</div><header class=article-meta><p class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>&nbsp; 4 minute read &nbsp;</p></header><h2 id=resource-types>Resource Types</h2><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-OpenModel>OpenModel</a></li></ul><h2 id=llmaz-io-v1alpha1-OpenModel><code>OpenModel</code></h2><p><strong>Appears in:</strong></p><p>OpenModel is the Schema for the open models API</p><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>apiVersion</code><br>string</td><td><code>llmaz.io/v1alpha1</code></td></tr><tr><td><code>kind</code><br>string</td><td><code>OpenModel</code></td></tr><tr><td><code>spec</code> <b>[Required]</b><br><a href=#llmaz-io-v1alpha1-ModelSpec><code>ModelSpec</code></a></td><td><span class=text-muted>No description provided.</span></td></tr><tr><td><code>status</code> <b>[Required]</b><br><a href=#llmaz-io-v1alpha1-ModelStatus><code>ModelStatus</code></a></td><td><span class=text-muted>No description provided.</span></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-Flavor><code>Flavor</code></h2><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-InferenceConfig>InferenceConfig</a></li></ul><p>Flavor defines the accelerator requirements for a model and the necessary parameters
in autoscaling. Right now, it will be used in two places:</p><ul><li>Pod scheduling with node selectors specified.</li><li>Cluster autoscaling with essential parameters provided.</li></ul><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>name</code> <b>[Required]</b><br><a href=#llmaz-io-v1alpha1-FlavorName><code>FlavorName</code></a></td><td><p>Name represents the flavor name, which will be used in model claim.</p></td></tr><tr><td><code>limits</code><br><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#resourcelist-v1-core><code>k8s.io/api/core/v1.ResourceList</code></a></td><td><p>Limits defines the required accelerators to serve the model for each replica,
like &lt;nvidia.com/gpu: 8>. For multi-hosts cases, the limits here indicates
the resource requirements for each replica, usually equals to the TP size.
Not recommended to set the cpu and memory usage here:</p><ul><li>if using playground, you can define the cpu/mem usage at backendConfig.</li><li>if using inference service, you can define the cpu/mem at the container resources.
However, if you define the same accelerator resources at playground/service as well,
the resources will be overwritten by the flavor limit here.</li></ul></td></tr><tr><td><code>nodeSelector</code><br><code>map[string]string</code></td><td><p>NodeSelector represents the node candidates for Pod placements, if a node doesn't
meet the nodeSelector, it will be filtered out in the resourceFungibility scheduler plugin.
If nodeSelector is empty, it means every node is a candidate.</p></td></tr><tr><td><code>params</code><br><code>map[string]string</code></td><td><p>Params stores other useful parameters and will be consumed by cluster-autoscaler / Karpenter
for autoscaling or be defined as model parallelism parameters like TP or PP size.
E.g. with autoscaling, when scaling up nodes with 8x Nvidia A00, the parameter can be injected
with &lt;INSTANCE-TYPE: p4d.24xlarge> for AWS.
Preset parameters: TP, PP, INSTANCE-TYPE.</p></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-FlavorName><code>FlavorName</code></h2><p>(Alias of <code>string</code>)</p><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-Flavor>Flavor</a></li></ul><h2 id=llmaz-io-v1alpha1-InferenceConfig><code>InferenceConfig</code></h2><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-ModelSpec>ModelSpec</a></li></ul><p>InferenceConfig represents the inference configurations for the model.</p><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>flavors</code><br><a href=#llmaz-io-v1alpha1-Flavor><code>[]Flavor</code></a></td><td><p>Flavors represents the accelerator requirements to serve the model.
Flavors are fungible following the priority represented by the slice order.</p></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-ModelHub><code>ModelHub</code></h2><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-ModelSource>ModelSource</a></li></ul><p>ModelHub represents the model registry for model downloads.</p><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>name</code><br><code>string</code></td><td><p>Name refers to the model registry, such as huggingface.</p></td></tr><tr><td><code>modelID</code> <b>[Required]</b><br><code>string</code></td><td><p>ModelID refers to the model identifier on model hub,
such as meta-llama/Meta-Llama-3-8B.</p></td></tr><tr><td><code>filename</code> <b>[Required]</b><br><code>string</code></td><td><p>Filename refers to a specified model file rather than the whole repo.
This is helpful to download a specified GGUF model rather than downloading
the whole repo which includes all kinds of quantized models.
TODO: this is only supported with Huggingface, add support for ModelScope
in the near future.
Note: once filename is set, allowPatterns and ignorePatterns should be left unset.</p></td></tr><tr><td><code>revision</code><br><code>string</code></td><td><p>Revision refers to a Git revision id which can be a branch name, a tag, or a commit hash.</p></td></tr><tr><td><code>allowPatterns</code><br><code>[]string</code></td><td><p>AllowPatterns refers to files matched with at least one pattern will be downloaded.</p></td></tr><tr><td><code>ignorePatterns</code><br><code>[]string</code></td><td><p>IgnorePatterns refers to files matched with any of the patterns will not be downloaded.</p></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-ModelName><code>ModelName</code></h2><p>(Alias of <code>string</code>)</p><p><strong>Appears in:</strong></p><ul><li><p><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-ModelRef>ModelRef</a></p></li><li><p><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-ModelSpec>ModelSpec</a></p></li></ul><h2 id=llmaz-io-v1alpha1-ModelRef><code>ModelRef</code></h2><p><strong>Appears in:</strong></p><p>ModelRef refers to a created Model with it's role.</p><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>name</code> <b>[Required]</b><br><a href=#llmaz-io-v1alpha1-ModelName><code>ModelName</code></a></td><td><p>Name represents the model name.</p></td></tr><tr><td><code>role</code><br><a href=#llmaz-io-v1alpha1-ModelRole><code>ModelRole</code></a></td><td><p>Role represents the model role once more than one model is required.
Such as a draft role, which means running with SpeculativeDecoding,
and default arguments for backend will be searched in backendRuntime
with the name of speculative-decoding.</p></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-ModelRole><code>ModelRole</code></h2><p>(Alias of <code>string</code>)</p><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-ModelRef>ModelRef</a></li></ul><h2 id=llmaz-io-v1alpha1-ModelSource><code>ModelSource</code></h2><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-ModelSpec>ModelSpec</a></li></ul><p>ModelSource represents the source of the model.
Only one model source will be used.</p><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>modelHub</code><br><a href=#llmaz-io-v1alpha1-ModelHub><code>ModelHub</code></a></td><td><p>ModelHub represents the model registry for model downloads.</p></td></tr><tr><td><code>uri</code><br><a href=#llmaz-io-v1alpha1-URIProtocol><code>URIProtocol</code></a></td><td><p>URI represents a various kinds of model sources following the uri protocol, protocol://, e.g.</p><ul><li>oss://./</li><li>ollama://llama3.3</li><li>host://</li></ul></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-ModelSpec><code>ModelSpec</code></h2><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-OpenModel>OpenModel</a></li></ul><p>ModelSpec defines the desired state of Model</p><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>familyName</code> <b>[Required]</b><br><a href=#llmaz-io-v1alpha1-ModelName><code>ModelName</code></a></td><td><p>FamilyName represents the model type, like llama2, which will be auto injected
to the labels with the key of <code>llmaz.io/model-family-name</code>.</p></td></tr><tr><td><code>source</code> <b>[Required]</b><br><a href=#llmaz-io-v1alpha1-ModelSource><code>ModelSource</code></a></td><td><p>Source represents the source of the model, there're several ways to load
the model such as loading from huggingface, OCI registry, s3, host path and so on.</p></td></tr><tr><td><code>inferenceConfig</code> <b>[Required]</b><br><a href=#llmaz-io-v1alpha1-InferenceConfig><code>InferenceConfig</code></a></td><td><p>InferenceConfig represents the inference configurations for the model.</p></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-ModelStatus><code>ModelStatus</code></h2><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-OpenModel>OpenModel</a></li></ul><p>ModelStatus defines the observed state of Model</p><table class=table><thead><tr><th width=30%>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>conditions</code> <b>[Required]</b><br><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#condition-v1-meta><code>[]k8s.io/apimachinery/pkg/apis/meta/v1.Condition</code></a></td><td><p>Conditions represents the Inference condition.</p></td></tr></tbody></table><h2 id=llmaz-io-v1alpha1-URIProtocol><code>URIProtocol</code></h2><p>(Alias of <code>string</code>)</p><p><strong>Appears in:</strong></p><ul><li><a href=/docs/reference/core.v1alpha1/#llmaz-io-v1alpha1-ModelSource>ModelSource</a></li></ul><p>URIProtocol represents the protocol of the URI.</p><style>.feedback--answer{display:inline-block}.feedback--answer-no{margin-left:1em}.feedback--response{display:none;margin-top:1em}.feedback--response__visible{display:block}</style><div class=d-print-none><h2 class=feedback--title>Feedback</h2><p class=feedback--question>Was this page helpful?</p><button class="btn btn-primary mb-4 feedback--answer feedback--answer-yes">Yes</button>
<button class="btn btn-primary mb-4 feedback--answer feedback--answer-no">No</button><p class="feedback--response feedback--response-yes">Glad to hear it! Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p><p class="feedback--response feedback--response-no">Sorry to hear that. Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p></div><script>const yesButton=document.querySelector(".feedback--answer-yes"),noButton=document.querySelector(".feedback--answer-no"),yesResponse=document.querySelector(".feedback--response-yes"),noResponse=document.querySelector(".feedback--response-no"),disableButtons=()=>{yesButton.disabled=!0,noButton.disabled=!0},sendFeedback=e=>{if(typeof gtag!="function")return;gtag("event","page_helpful",{event_category:"Helpful",event_label:window.location.pathname,value:e})};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(100)}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(0)})</script><br><div class=td-page-meta__lastmod>Last modified June 10, 2025: <a href=https://github.com/InftyAI/llmaz/commit/9a3167ee9b61eaee6a1ec3b0dc37fdc8a147d27f>Proposal for karpenter intergation (#439) (9a3167e)</a></div></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title aria-label><a target=_blank rel=noopener href aria-label><i></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/InftyAI/llmaz aria-label=GitHub><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=X aria-label=X><a target=_blank rel=noopener href=https://x.com/InftyAI aria-label=X><i class="fab fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Slack aria-label=Slack><a target=_blank rel=noopener href=https://inftyai.slack.com/ aria-label=Slack><i class="fab fa-slack"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2025
<span class=td-footer__authors>The InftyAI Team</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.69e2c1ae9320465ab10236d9ef752c6a4442c54b48b883b17c497b7c7d96a796.js integrity="sha256-aeLBrpMgRlqxAjbZ73UsakRCxUtIuIOxfEl7fH2Wp5Y=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>