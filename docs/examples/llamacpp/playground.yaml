apiVersion: inference.llmaz.io/v1alpha1
kind: Playground
metadata:
  name: qwen2-0--5b
spec:
  replicas: 1
  modelClaim:
    modelName: qwen2-0--5b-gguf
  backendRuntimeConfig:
    backendName: llamacpp
    args:
      - -fa # use flash attention
