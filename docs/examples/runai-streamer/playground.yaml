
---
apiVersion: llmaz.io/v1alpha1
kind: OpenModel
metadata:
  name: deepseek-r1-distill-qwen-1-5b
  annotations:
    llmaz.io/skip-model-loader: "true"
spec:
  familyName: deepseek
  source:
    uri: s3://cr7258/DeepSeek-R1-Distill-Qwen-1.5B
  inferenceConfig:
    flavors:
      - name: t4 # GPU type
        limits:
          nvidia.com/gpu: 1
---
apiVersion: inference.llmaz.io/v1alpha1
kind: Playground
metadata:
  name: deepseek-r1-distill-qwen-1-5b
  annotations:
    llmaz.io/skip-model-loader: "true"
spec:
  replicas: 1
  modelClaim:
    modelName: deepseek-r1-distill-qwen-1-5b
  backendRuntimeConfig:
    backendName: vllm # currently, only vllm supports runai streamer
