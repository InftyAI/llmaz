<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Karpenter | llmaz</title>
<meta name=description content="Karpenter automatically launches just the right compute resources to handle your cluster’s applications, but it is built to adhere to the scheduling decisions of kube-scheduler, so it’s certainly possible we would run across some cases where Karpenter makes incorrect decisions when the InftyAI scheduler is in the mix.
We forked the Karpenter project and re-complie the karpenter image for cloud providers like AWS, and you can find the details in this proposal. This document provides deployment steps to install and configure Customized Karpenter in an EKS cluster."><meta property="og:url" content="https://llmaz.inftyai.com/docs/integrations/karpenter/"><meta property="og:site_name" content="llmaz"><meta property="og:title" content="Karpenter"><meta property="og:description" content="Karpenter automatically launches just the right compute resources to handle your cluster’s applications, but it is built to adhere to the scheduling decisions of kube-scheduler, so it’s certainly possible we would run across some cases where Karpenter makes incorrect decisions when the InftyAI scheduler is in the mix.
We forked the Karpenter project and re-complie the karpenter image for cloud providers like AWS, and you can find the details in this proposal. This document provides deployment steps to install and configure Customized Karpenter in an EKS cluster."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2025-07-03T17:04:19+08:00"><meta itemprop=name content="Karpenter"><meta itemprop=description content="Karpenter automatically launches just the right compute resources to handle your cluster’s applications, but it is built to adhere to the scheduling decisions of kube-scheduler, so it’s certainly possible we would run across some cases where Karpenter makes incorrect decisions when the InftyAI scheduler is in the mix.
We forked the Karpenter project and re-complie the karpenter image for cloud providers like AWS, and you can find the details in this proposal. This document provides deployment steps to install and configure Customized Karpenter in an EKS cluster."><meta itemprop=dateModified content="2025-07-03T17:04:19+08:00"><meta itemprop=wordCount content="1086"><meta name=twitter:card content="summary"><meta name=twitter:title content="Karpenter"><meta name=twitter:description content="Karpenter automatically launches just the right compute resources to handle your cluster’s applications, but it is built to adhere to the scheduling decisions of kube-scheduler, so it’s certainly possible we would run across some cases where Karpenter makes incorrect decisions when the InftyAI scheduler is in the mix.
We forked the Karpenter project and re-complie the karpenter image for cloud providers like AWS, and you can find the details in this proposal. This document provides deployment steps to install and configure Customized Karpenter in an EKS cluster."><link rel=preload href=/scss/main.min.df756438a7e020f7456327e32660cfd018c35e49c250d72b637e5a0fdc7f595c.css as=style integrity="sha256-33VkOKfgIPdFYyfjJmDP0BjDXknCUNcrY35aD9x/WVw=" crossorigin=anonymous><link href=/scss/main.min.df756438a7e020f7456327e32660cfd018c35e49c250d72b637e5a0fdc7f595c.css rel=stylesheet integrity="sha256-33VkOKfgIPdFYyfjJmDP0BjDXknCUNcrY35aD9x/WVw=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-page><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg version="1.2" viewBox="0 0 29 30" width="29" height="30"><style>.a{fill:#fff;stroke:#e94751;stroke-linecap:round;stroke-linejoin:round;stroke-width:.4}</style><path class="a" d="m14.3.0-13.7 6.5c-.2.0-.2.3.0.4L3 8.1q.2.1.4.0l11-5.5q.2.0.3.0l1.9.9c.3.2.2.3.0.4L6 9.3c-.2.1-.2.3.0.4L8.5 11q.1.1.3.0l10.8-6q.1.0.2.0l2.5 1.2c.2.0.2.3.0.4l-10.1 5.5c-.4.1-.6.5-.2.8l2.3 1.2c.2.1.4.0.5.0L28.2 7c.4-.2.4-.7.0-.9L14.7.0q-.2.0-.4.0z"/><path class="a" d="m29 8.8v3.3l-.1.1-9.3 12.5 9.1-4.9c.1.0.3.0.3.2v3l-13.2 7c-.2.1-.6-.1-.6-.4v-3.5q0-.1.1-.1l9.3-12.2s0-.1-.1.0l-9 5.4c-.1.1-.3.0-.3-.2v-3c0-.3.2-.5.4-.6l12.9-6.9c.2-.1.5.0.5.3z"/><path class="a" d="m13.6 15.4-12.9-6.6c-.3-.2-.7.1-.7.4v13.3q0 .1.1.2l2.1 1c.2.1.5-.1.5-.4v-3.2l7.5 3.8v4.3q0 .2.2.3l2.7 1.5c.3.1.7-.1.7-.5V15.9c0-.2-.1-.4-.2-.5zM2.7 17.3v-3.4c0-.1.2-.2.3-.1l7 3.4c.1.1.2.3.2.5V21z"/></svg></span><span class=navbar-brand__name>llmaz</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class="nav-link active" href=/docs/><span>Documentation</span></a></li><li class=nav-item><a class=nav-link href=/docs/reference/><span>Reference</span></a></li><li class=nav-item><a class=nav-link href=/blog/><span>Blog</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><ul class=dropdown-menu><li><a class=dropdown-item href=/docs>latest</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.24adf07bddfc25b8b15923d1fc77bcc4.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><div id=content-mobile><form class="td-sidebar__search d-flex align-items-center"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.24adf07bddfc25b8b15923d1fc77bcc4.json data-offline-search-base-href=/ data-offline-search-max-results=10></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form></div><div id=content-desktop></div><nav class="td-sidebar-nav collapse td-sidebar-nav--search-disabled" id=td-section-nav><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-docs-li><a href=/docs/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-docs><span>Documentation</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-docsgetting-started-li><a href=/docs/getting-started/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsgetting-started><span>Getting Started</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsgetting-startedprerequisites-li><a href=/docs/getting-started/prerequisites/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedprerequisites><span>Prerequisites</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsgetting-startedinstallation-li><a href=/docs/getting-started/installation/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedinstallation><span>Installation</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsgetting-startedbasic-usage-li><a href=/docs/getting-started/basic-usage/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedbasic-usage><span>Basic Usage</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-docsfeatures-li><a href=/docs/features/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsfeatures><span>Features</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsfeaturesbroad-backends-li><a href=/docs/features/broad-backends/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsfeaturesbroad-backends><span>Broad Inference Backends Support</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsfeaturesheterogeneous-cluster-support-li><a href=/docs/features/heterogeneous-cluster-support/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsfeaturesheterogeneous-cluster-support><span>Heterogeneous Cluster Support</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsfeaturesdistributed_inference-li><a href=/docs/features/distributed_inference/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsfeaturesdistributed_inference><span>Distributed Inference</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-docsintegrations-li><a href=/docs/integrations/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsintegrations><span>Integrations</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsintegrationsenvoy-ai-gateway-li><a href=/docs/integrations/envoy-ai-gateway/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsintegrationsenvoy-ai-gateway><span>Envoy AI Gateway</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-docsintegrationskarpenter-li><a href=/docs/integrations/karpenter/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-docsintegrationskarpenter><span class=td-sidebar-nav-active-item>Karpenter</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsintegrationsopen-webui-li><a href=/docs/integrations/open-webui/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsintegrationsopen-webui><span>Open-WebUI</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsintegrationsprometheus-operator-li><a href=/docs/integrations/prometheus-operator/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsintegrationsprometheus-operator><span>Prometheus Operator</span></a></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsdevelop-li><a href=/docs/develop/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsdevelop><span>Develop Guidance</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-docsreference-li><a href=/docs/reference/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-docsreference><span>Reference</span></a><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsreferencecorev1alpha1-li><a href=/docs/reference/core.v1alpha1/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsreferencecorev1alpha1><span>llmaz core API</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-docsreferenceinferencev1alpha1-li><a href=/docs/reference/inference.v1alpha1/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-docsreferenceinferencev1alpha1><span>llmaz inference API</span></a></li></ul></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"><a href=https://github.com/InftyAI/llmaz/tree/main/site/content/en/docs/integrations/karpenter.md class="td-page-meta--view td-page-meta__view" target=_blank rel=noopener><i class="fa-solid fa-file-lines fa-fw"></i> View page source</a>
<a href=https://github.com/InftyAI/llmaz/edit/main/site/content/en/docs/integrations/karpenter.md class="td-page-meta--edit td-page-meta__edit" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Edit this page</a>
<a href="https://github.com/InftyAI/llmaz/new/main/site/content/en/docs/integrations?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class="td-page-meta--child td-page-meta__child" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Create child page</a>
<a href="https://github.com/InftyAI/llmaz/issues/new?title=Karpenter" class="td-page-meta--issue td-page-meta__issue" target=_blank rel=noopener><i class="fa-solid fa-list-check fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/InftyAI/llmaz/issues/new class="td-page-meta--project td-page-meta__project-issue" target=_blank rel=noopener><i class="fa-solid fa-list-check fa-fw"></i> Create project issue</a>
<a id=print href=/docs/integrations/_print/><i class="fa-solid fa-print fa-fw"></i> Print entire section</a></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#how-to-use>How to use</a><ul><li><a href=#set-environment-variables>Set environment variables</a></li><li><a href=#create-a-cluster-and-add-karpenter>Create a cluster and add Karpenter</a></li><li><a href=#install-the-gpu-operator>Install the gpu operator</a></li><li><a href=#install-llmaz-with-inftyai-scheduler-enabled>Install llmaz with InftyAI scheduler enabled</a></li><li><a href=#configure-karpenter-with-customized-image>Configure Karpenter with customized image</a></li></ul></li><li><a href=#basic-example>Basic Example</a></li></ul></nav></div><div class="taxonomy taxonomy-terms-cloud taxo-categories"><h5 class=taxonomy-title>Categories</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://llmaz.inftyai.com/categories/inference/ data-taxonomy-term=inference><span class=taxonomy-label>Inference</span><span class=taxonomy-count>1</span></a></li></ul></div><div class="taxonomy taxonomy-terms-cloud taxo-tags"><h5 class=taxonomy-title>Tags</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://llmaz.inftyai.com/tags/release-note/ data-taxonomy-term=release-note><span class=taxonomy-label>Release-Note</span><span class=taxonomy-count>1</span></a></li></ul></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><nav aria-label=breadcrumb class=td-breadcrumbs><ol class=breadcrumb><li class=breadcrumb-item><a href=/docs/>Documentation</a></li><li class=breadcrumb-item><a href=/docs/integrations/>Integrations</a></li><li class="breadcrumb-item active" aria-current=page>Karpenter</li></ol></nav><div class=td-content><h1>Karpenter</h1><header class=article-meta><p class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>&nbsp; 6 minute read &nbsp;</p></header><p><a href=https://github.com/kubernetes-sigs/karpenter>Karpenter</a> automatically launches just the right compute resources to handle your cluster&rsquo;s applications, but it is built to adhere to the scheduling decisions of kube-scheduler, so it&rsquo;s certainly possible we would run across some cases where Karpenter makes incorrect decisions when the InftyAI scheduler is in the mix.</p><p>We forked the Karpenter project and re-complie the karpenter image for cloud providers like AWS, and you can find the details in <a href=https://github.com/InftyAI/llmaz/blob/main/docs/proposals/106-spot-instance-karpenter/README.md>this proposal</a>. This document provides deployment steps to install and configure Customized Karpenter in an EKS cluster.</p><h2 id=how-to-use>How to use</h2><h3 id=set-environment-variables>Set environment variables</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>KARPENTER_NAMESPACE</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;kube-system&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>KARPENTER_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;1.5.0&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>K8S_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;1.32&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>AWS_PARTITION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;aws&#34;</span> <span style=color:#8f5902;font-style:italic># if you are not using standard partitions, you may need to configure to aws-cn / aws-us-gov</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>CLUSTER_NAME</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>USER</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>-karpenter-demo&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>AWS_DEFAULT_REGION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;us-west-2&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>AWS_ACCOUNT_ID</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#204a87;font-weight:700>$(</span>aws sts get-caller-identity --query Account --output text<span style=color:#204a87;font-weight:700>)</span><span style=color:#4e9a06>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>TEMPOUT</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#204a87;font-weight:700>$(</span>mktemp<span style=color:#204a87;font-weight:700>)</span><span style=color:#4e9a06>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>ALIAS_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#204a87;font-weight:700>$(</span>aws ssm get-parameter --name <span style=color:#4e9a06>&#34;/aws/service/eks/optimized-ami/</span><span style=color:#4e9a06>${</span><span style=color:#000>K8S_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>/amazon-linux-2023/x86_64/standard/recommended/image_id&#34;</span> --query Parameter.Value <span style=color:#000;font-weight:700>|</span> xargs aws ec2 describe-images --query <span style=color:#4e9a06>&#39;Images[0].Name&#39;</span> --image-ids <span style=color:#000;font-weight:700>|</span> sed -r <span style=color:#4e9a06>&#39;s/^.*(v[[:digit:]]+).*$/\1/&#39;</span><span style=color:#204a87;font-weight:700>)</span><span style=color:#4e9a06>&#34;</span>
</span></span></code></pre></div><p>If you open a new shell to run steps in this procedure, you need to set some or all of the environment variables again. To remind yourself of these values, type:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#204a87>echo</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_NAMESPACE</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>K8S_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>AWS_DEFAULT_REGION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>AWS_ACCOUNT_ID</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>TEMPOUT</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>ALIAS_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span>
</span></span></code></pre></div><h3 id=create-a-cluster-and-add-karpenter>Create a cluster and add Karpenter</h3><p>Please refer to the <a href=https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html>Getting Started with Karpenter</a> to create a cluster and add Karpenter.</p><h3 id=install-the-gpu-operator>Install the gpu operator</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>helm repo add nvidia https://helm.ngc.nvidia.com/nvidia <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    <span style=color:#ce5c00;font-weight:700>&amp;&amp;</span> helm repo update
</span></span><span style=display:flex><span>helm install --wait --generate-name <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    -n gpu-operator --create-namespace <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    nvidia/gpu-operator <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    --version<span style=color:#ce5c00;font-weight:700>=</span>v25.3.0
</span></span></code></pre></div><h3 id=install-llmaz-with-inftyai-scheduler-enabled>Install llmaz with InftyAI scheduler enabled</h3><p>Please refer to <a href=/docs/features/heterogeneous-cluster-support/>heterogeneous cluster support</a>.</p><h3 id=configure-karpenter-with-customized-image>Configure Karpenter with customized image</h3><p>We need to assign the <code>karpenter-core-llmaz</code> cluster role to the <code>karpenter</code> service account and update the karpenter image to the customized one.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#4e9a06>&lt;&lt;EOF | envsubst | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: rbac.authorization.k8s.io/v1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: ClusterRoleBinding
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter-core-llmaz
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>roleRef:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  apiGroup: rbac.authorization.k8s.io
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  kind: ClusterRole
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter-core-llmaz
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>subjects:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>- kind: ServiceAccount
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  namespace: ${KARPENTER_NAMESPACE}
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>---
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: rbac.authorization.k8s.io/v1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: ClusterRole
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter-core-llmaz
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>rules:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>- apiGroups: [&#34;llmaz.io&#34;]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  resources: [&#34;openmodels&#34;]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  verbs: [&#34;get&#34;, &#34;list&#34;, &#34;watch&#34;]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter --version <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> --namespace <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_NAMESPACE</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> --create-namespace <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set <span style=color:#4e9a06>&#34;settings.clusterName=</span><span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set <span style=color:#4e9a06>&#34;settings.interruptionQueue=</span><span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.requests.cpu<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.requests.memory<span style=color:#ce5c00;font-weight:700>=</span>1Gi <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.limits.cpu<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.limits.memory<span style=color:#ce5c00;font-weight:700>=</span>1Gi <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --wait <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.image.repository<span style=color:#ce5c00;font-weight:700>=</span>inftyai/karpenter-provider-aws <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set <span style=color:#4e9a06>&#34;controller.image.tag=</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.image.digest<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;&#34;</span>
</span></span></code></pre></div><h2 id=basic-example>Basic Example</h2><ol><li>Create a gpu node pool</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#4e9a06>&lt;&lt;EOF | envsubst | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: karpenter.k8s.aws/v1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: E</span>C2NodeClass
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: llmaz-demo            <span style=color:#8f5902;font-style:italic># you can change the name to a more meaningful one, please align with the node pool&#39;s nodeClassRef.</span>
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  amiSelectorTerms:
</span></span><span style=display:flex><span>  - alias: al2023@<span style=color:#4e9a06>${</span><span style=color:#000>ALIAS_VERSION</span><span style=color:#4e9a06>}</span>
</span></span><span style=display:flex><span>  blockDeviceMappings:
</span></span><span style=display:flex><span>  <span style=color:#8f5902;font-style:italic># the default volume size of the selected AMI is 20Gi, it is not enough for kubelet to pull</span>
</span></span><span style=display:flex><span>  <span style=color:#8f5902;font-style:italic># the images and run the workloads. So we need to map a larger volume to the root device. </span>
</span></span><span style=display:flex><span>  <span style=color:#8f5902;font-style:italic># You can change the volume size to a larger value according to your actual needs.</span>
</span></span><span style=display:flex><span>  - deviceName: /dev/xvda
</span></span><span style=display:flex><span>    ebs:
</span></span><span style=display:flex><span>      deleteOnTermination: <span style=color:#204a87>true</span>
</span></span><span style=display:flex><span>      volumeSize: 50Gi     
</span></span><span style=display:flex><span>      volumeType: gp3
</span></span><span style=display:flex><span>  role: KarpenterNodeRole-<span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span>          <span style=color:#8f5902;font-style:italic># replace with your cluster name</span>
</span></span><span style=display:flex><span>  securityGroupSelectorTerms:
</span></span><span style=display:flex><span>  - tags:
</span></span><span style=display:flex><span>      karpenter.sh/discovery: <span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span>      <span style=color:#8f5902;font-style:italic># replace with your cluster name</span>
</span></span><span style=display:flex><span>  subnetSelectorTerms:
</span></span><span style=display:flex><span>  - tags:
</span></span><span style=display:flex><span>      karpenter.sh/discovery: <span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span>      <span style=color:#8f5902;font-style:italic># replace with your cluster name</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: karpenter.sh/v1
</span></span><span style=display:flex><span>kind: NodePool
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: llmaz-demo-gpu-nodepool  <span style=color:#8f5902;font-style:italic># you can change the name to a more meaningful one. </span>
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  disruption:
</span></span><span style=display:flex><span>    budgets:
</span></span><span style=display:flex><span>    - nodes: 10%
</span></span><span style=display:flex><span>    consolidateAfter: 5m        
</span></span><span style=display:flex><span>    consolidationPolicy: WhenEmptyOrUnderutilized
</span></span><span style=display:flex><span>  limits:  <span style=color:#8f5902;font-style:italic># You can change the limits to match your actual needs.</span>
</span></span><span style=display:flex><span>    cpu: <span style=color:#0000cf;font-weight:700>1000</span>
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      expireAfter: 720h
</span></span><span style=display:flex><span>      nodeClassRef:
</span></span><span style=display:flex><span>        group: karpenter.k8s.aws
</span></span><span style=display:flex><span>        kind: EC2NodeClass
</span></span><span style=display:flex><span>        name: llmaz-demo
</span></span><span style=display:flex><span>      requirements:
</span></span><span style=display:flex><span>      - key: kubernetes.io/arch
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:
</span></span><span style=display:flex><span>        - amd64
</span></span><span style=display:flex><span>      - key: kubernetes.io/os
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:
</span></span><span style=display:flex><span>        - linux
</span></span><span style=display:flex><span>      - key: karpenter.sh/capacity-type
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:
</span></span><span style=display:flex><span>        - spot
</span></span><span style=display:flex><span>      - key: karpenter.k8s.aws/instance-family
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:                                <span style=color:#8f5902;font-style:italic># replace with your instance-family with gpu supported</span>
</span></span><span style=display:flex><span>        - g4dn
</span></span><span style=display:flex><span>        - g5g
</span></span><span style=display:flex><span>      taints:
</span></span><span style=display:flex><span>      - effect: NoSchedule
</span></span><span style=display:flex><span>        key: nvidia.com/gpu
</span></span><span style=display:flex><span>        value: <span style=color:#4e9a06>&#34;true&#34;</span>
</span></span></code></pre></div><ol start=2><li>Deploy a model with flavors</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#4e9a06>&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: llmaz.io/v1alpha1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: OpenModel
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>spec:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  familyName: qwen2
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  source:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    modelHub:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      modelID: Qwen/Qwen2-0.5B-Instruct
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  inferenceConfig:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    flavors:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # The g5g instance family in the aws cloud can provide the t4g GPU type.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # we define the instance family in the node pool like llmaz-demo-gpu-nodepool.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      - name: t4g
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        limits:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          nvidia.com/gpu: 1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The flavorName is not recongnized by the Karpenter, so we need to specify the
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # instance-gpu-name via nodeSelector to match the t4g GPU type when node is provisioned
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # by Karpenter from multiple node pools.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # When you only have a single node pool to provision the GPU instance and the node pool
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # only has one GPU type, it is okay to not specify the nodeSelector. But in practice,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # it is better to specify the nodeSelector to make the provisioned node more predictable.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The available node labels for selecting the target GPU device is listed below:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-count
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-manufacturer
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-memory
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-name
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        nodeSelector:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          karpenter.k8s.aws/instance-gpu-name: t4g
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # The g4dn instance family in the aws cloud can provide the t4 GPU type.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # we define the instance family in the node pool like llmaz-demo-gpu-nodepool.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      - name: t4
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        limits:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          nvidia.com/gpu: 1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The flavorName is not recongnized by the Karpenter, so we need to specify the
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # instance-gpu-name via nodeSelector to match the t4 GPU type when node is provisioned
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # by Karpenter from multiple node pools.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # When you only have a single node pool to provision the GPU instance and the node pool
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # only has one GPU type, it is okay to not specify the nodeSelector. But in practice,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # it is better to specify the nodeSelector to make the provisioned node more predictable.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The available node labels for selecting the target GPU device is listed below:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-count
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-manufacturer
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-memory
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-name
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        nodeSelector:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          karpenter.k8s.aws/instance-gpu-name: t4
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>---
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># Currently, the Playground resource type does not support to configure tolerations
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># for the generated pods. But luckily, when a pod with the `nvidia.com/gpu` resource  
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># is created on the eks cluster, the generated pod will be tweaked with the following
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># tolerations:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#   - effect: NoExecute
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#      key: node.kubernetes.io/not-ready
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#      operator: Exists
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#      tolerationSeconds: 300
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#   - effect: NoExecute
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     key: node.kubernetes.io/unreachable
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     operator: Exists
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     tolerationSeconds: 300
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#   - effect: NoSchedule
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     key: nvidia.com/gpu
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     operator: Exists
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: inference.llmaz.io/v1alpha1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: Playground
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  labels:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    llmaz.io/model-name: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>spec:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  backendRuntimeConfig:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    backendName: tgi
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    # Due to the limitation of our aws account, we have to decrease the resources to match
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    # the avaliable instance type which is g4dn.xlarge. If your account has no such limitation,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    # you can remove the custom resources settings below.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    resources:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      limits:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        cpu: &#34;2&#34;
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        memory: 4Gi
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      requests:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        cpu: &#34;2&#34;
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        memory: 4Gi
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  modelClaim:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    modelName: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  replicas: 1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>EOF</span>
</span></span></code></pre></div><style>.feedback--answer{display:inline-block}.feedback--answer-no{margin-left:1em}.feedback--response{display:none;margin-top:1em}.feedback--response__visible{display:block}</style><div class=d-print-none><h2 class=feedback--title>Feedback</h2><p class=feedback--question>Was this page helpful?</p><button class="btn btn-primary mb-4 feedback--answer feedback--answer-yes">Yes</button>
<button class="btn btn-primary mb-4 feedback--answer feedback--answer-no">No</button><p class="feedback--response feedback--response-yes">Glad to hear it! Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p><p class="feedback--response feedback--response-no">Sorry to hear that. Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p></div><script>const yesButton=document.querySelector(".feedback--answer-yes"),noButton=document.querySelector(".feedback--answer-no"),yesResponse=document.querySelector(".feedback--response-yes"),noResponse=document.querySelector(".feedback--response-no"),disableButtons=()=>{yesButton.disabled=!0,noButton.disabled=!0},sendFeedback=e=>{if(typeof gtag!="function")return;gtag("event","page_helpful",{event_category:"Helpful",event_label:window.location.pathname,value:e})};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(100)}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(0)})</script><br><div class=td-page-meta__lastmod>Last modified July 3, 2025: <a href=https://github.com/InftyAI/llmaz/commit/2bdc3768d4c2f37804386498fd9b0e6910e8346c>chore: adopt golangci-lint v2 (#474) (2bdc376)</a></div></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title aria-label><a target=_blank rel=noopener href aria-label><i></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/InftyAI/llmaz aria-label=GitHub><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=X aria-label=X><a target=_blank rel=noopener href=https://x.com/InftyAI aria-label=X><i class="fab fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Slack aria-label=Slack><a target=_blank rel=noopener href=https://inftyai.slack.com/ aria-label=Slack><i class="fab fa-slack"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2025
<span class=td-footer__authors>The InftyAI Team</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.69e2c1ae9320465ab10236d9ef752c6a4442c54b48b883b17c497b7c7d96a796.js integrity="sha256-aeLBrpMgRlqxAjbZ73UsakRCxUtIuIOxfEl7fH2Wp5Y=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>