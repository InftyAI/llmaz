<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://llmaz.inftyai.com/docs/integrations/><link rel=alternate type=application/rss+xml href=https://llmaz.inftyai.com/docs/integrations/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Integrations | llmaz</title>
<meta name=description content="This section contains the llmaz integration information."><meta property="og:url" content="https://llmaz.inftyai.com/docs/integrations/"><meta property="og:site_name" content="llmaz"><meta property="og:title" content="Integrations"><meta property="og:description" content="This section contains the llmaz integration information."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Integrations"><meta itemprop=description content="This section contains the llmaz integration information."><meta itemprop=dateModified content="2025-09-04T16:30:28+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Integrations"><meta name=twitter:description content="This section contains the llmaz integration information."><link rel=preload href=/scss/main.min.e8bfe7c2c9da20bc5c4650ed3666e1af93397efb4155feece69f60b4ebfe2c4b.css as=style integrity="sha256-6L/nwsnaILxcRlDtNmbhr5M5fvtBVf7s5p9gtOv+LEs=" crossorigin=anonymous><link href=/scss/main.min.e8bfe7c2c9da20bc5c4650ed3666e1af93397efb4155feece69f60b4ebfe2c4b.css rel=stylesheet integrity="sha256-6L/nwsnaILxcRlDtNmbhr5M5fvtBVf7s5p9gtOv+LEs=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg version="1.2" viewBox="0 0 29 30" width="29" height="30"><style>.a{fill:#fff;stroke:#e94751;stroke-linecap:round;stroke-linejoin:round;stroke-width:.4}</style><path class="a" d="m14.3.0-13.7 6.5c-.2.0-.2.3.0.4L3 8.1q.2.1.4.0l11-5.5q.2.0.3.0l1.9.9c.3.2.2.3.0.4L6 9.3c-.2.1-.2.3.0.4L8.5 11q.1.1.3.0l10.8-6q.1.0.2.0l2.5 1.2c.2.0.2.3.0.4l-10.1 5.5c-.4.1-.6.5-.2.8l2.3 1.2c.2.1.4.0.5.0L28.2 7c.4-.2.4-.7.0-.9L14.7.0q-.2.0-.4.0z"/><path class="a" d="m29 8.8v3.3l-.1.1-9.3 12.5 9.1-4.9c.1.0.3.0.3.2v3l-13.2 7c-.2.1-.6-.1-.6-.4v-3.5q0-.1.1-.1l9.3-12.2s0-.1-.1.0l-9 5.4c-.1.1-.3.0-.3-.2v-3c0-.3.2-.5.4-.6l12.9-6.9c.2-.1.5.0.5.3z"/><path class="a" d="m13.6 15.4-12.9-6.6c-.3-.2-.7.1-.7.4v13.3q0 .1.1.2l2.1 1c.2.1.5-.1.5-.4v-3.2l7.5 3.8v4.3q0 .2.2.3l2.7 1.5c.3.1.7-.1.7-.5V15.9c0-.2-.1-.4-.2-.5zM2.7 17.3v-3.4c0-.1.2-.2.3-.1l7 3.4c.1.1.2.3.2.5V21z"/></svg></span><span class=navbar-brand__name>llmaz</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class="nav-link active" href=/docs/><span>Documentation</span></a></li><li class=nav-item><a class=nav-link href=/docs/reference/><span>Reference</span></a></li><li class=nav-item><a class=nav-link href=/blog/><span>Blog</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><ul class=dropdown-menu><li><a class=dropdown-item href=/docs>latest</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.24adf07bddfc25b8b15923d1fc77bcc4.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/integrations/>Return to the regular view of this page</a>.</p></div><h1 class=title>Integrations</h1><div class=lead>This section contains the llmaz integration information.</div><ul><li>1: <a href=#pg-4883ef24b3c01ce986dd46f3062ba8ef>Envoy AI Gateway</a></li><li>2: <a href=#pg-906a54d18dbae3015ce13346aa74506c>Karpenter</a></li><li>3: <a href=#pg-f489e01e2e14261978166c1d55f39718>Open-WebUI</a></li><li>4: <a href=#pg-7d3a7a2ca4bbfe3c7b0f023d3eac77c6>Prometheus Operator</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-4883ef24b3c01ce986dd46f3062ba8ef>1 - Envoy AI Gateway</h1><p><a href=https://aigateway.envoyproxy.io/>Envoy AI Gateway</a> is an open source project for using Envoy Gateway
to handle request traffic from application clients to Generative AI services.</p><h2 id=how-to-use>How to use</h2><h3 id=enable-envoy-gateway-and-envoy-ai-gateway>Enable Envoy Gateway and Envoy AI Gateway</h3><p>Both of them are already enabled by default in <code>values.global.yaml</code> and will be deployed in llmaz-system.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>envoy-gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>envoy-ai-gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>However, <a href=https://gateway.envoyproxy.io/latest/install/install-helm/>Envoy Gateway</a> and <a href=https://aigateway.envoyproxy.io/docs/getting-started/>Envoy AI Gateway</a> can be deployed standalone in case you want to deploy them in other namespaces.</p><h3 id=basic-example>Basic Example</h3><p>To expose your models via Envoy Gateway, you need to create a GatewayClass, Gateway, and AIGatewayRoute. The following example shows how to do this.</p><p>We&rsquo;ll deploy two models <code>Qwen/Qwen2-0.5B-Instruct-GGUF</code> and <code>Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF</code> with llama.cpp (cpu only) and expose them via Envoy AI Gateway.</p><p>The full example is <a href=https://github.com/InftyAI/llmaz/blob/main/docs/examples/envoy-ai-gateway/basic.yaml>here</a>, apply it.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/InftyAI/llmaz/refs/heads/main/docs/examples/envoy-ai-gateway/basic.yaml
</span></span></code></pre></div><h3 id=query-ai-gateway-apis>Query AI Gateway APIs</h3><p>If Open-WebUI is enabled, you can chat via the webui (recommended), see <a href=/docs/integrations/open-webui/>documentation</a>. Otherwise, following the steps below to test the Envoy AI Gateway APIs.</p><p>I. Port-forwarding the <code>LoadBalancer</code> service in llmaz-system, like:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl -n llmaz-system port-forward <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  <span style=color:#204a87;font-weight:700>$(</span>kubectl -n llmaz-system get svc <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    -l gateway.envoyproxy.io/owning-gateway-name<span style=color:#ce5c00;font-weight:700>=</span>default-envoy-ai-gateway <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    -o name<span style=color:#204a87;font-weight:700>)</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  8080:80
</span></span></code></pre></div><p>II. Query <code>curl http://localhost:8080/v1/models | jq .</code>, available models will be listed. Expected response will look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;data&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>[</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;id&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;qwen2-0.5b&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;created&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1745327294</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;model&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;owned_by&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;Envoy AI Gateway&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>},</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;id&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;qwen2.5-coder&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;created&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1745327294</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;model&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;owned_by&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;Envoy AI Gateway&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>],</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;list&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>}</span>
</span></span></code></pre></div><p>III. Query <code>http://localhost:8080/v1/chat/completions</code> to chat with the model. Here, we ask the <code>qwen2-0.5b</code> model, the query will look like:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -H <span style=color:#4e9a06>&#34;Content-Type: application/json&#34;</span>     -d <span style=color:#4e9a06>&#39;{
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        &#34;model&#34;: &#34;qwen2-0.5b&#34;,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        &#34;messages&#34;: [
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>            {
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>                &#34;role&#34;: &#34;system&#34;,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>                &#34;content&#34;: &#34;Hi.&#34;
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>            }
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        ]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    }&#39;</span>     http://localhost:8080/v1/chat/completions <span style=color:#000;font-weight:700>|</span> jq .
</span></span></code></pre></div><p>Expected response will look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;choices&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>[</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;finish_reason&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;stop&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;index&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>0</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;message&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&#34;role&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;assistant&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&#34;content&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;Hello! How can I assist you today?&#34;</span>
</span></span><span style=display:flex><span>      <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>],</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;created&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1745327371</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;model&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;qwen2-0.5b&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;system_fingerprint&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;b5124-bc091a4d&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;chat.completion&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;usage&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;completion_tokens&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>10</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_tokens&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>10</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;total_tokens&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>20</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>},</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;id&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;chatcmpl-AODlT8xnf4OjJwpQH31XD4yehHLnurr0&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;timings&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_n&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>319.876</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_per_token_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>319.876</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_per_second&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>3.1262114069201816</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_n&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>10</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1309.393</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_per_token_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>130.9393</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_per_second&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>7.63712651587415</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>}</span>
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-906a54d18dbae3015ce13346aa74506c>2 - Karpenter</h1><p><a href=https://github.com/kubernetes-sigs/karpenter>Karpenter</a> automatically launches just the right compute resources to handle your cluster&rsquo;s applications, but it is built to adhere to the scheduling decisions of kube-scheduler, so it&rsquo;s certainly possible we would run across some cases where Karpenter makes incorrect decisions when the InftyAI scheduler is in the mix.</p><p>We forked the Karpenter project and re-complie the karpenter image for cloud providers like AWS, and you can find the details in <a href=https://github.com/InftyAI/llmaz/blob/main/docs/proposals/106-spot-instance-karpenter/README.md>this proposal</a>. This document provides deployment steps to install and configure Customized Karpenter in an EKS cluster.</p><h2 id=how-to-use>How to use</h2><h3 id=set-environment-variables>Set environment variables</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>KARPENTER_NAMESPACE</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;kube-system&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>KARPENTER_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;1.5.0&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>K8S_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;1.32&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>AWS_PARTITION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;aws&#34;</span> <span style=color:#8f5902;font-style:italic># if you are not using standard partitions, you may need to configure to aws-cn / aws-us-gov</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>CLUSTER_NAME</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>USER</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>-karpenter-demo&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>AWS_DEFAULT_REGION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;us-west-2&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>AWS_ACCOUNT_ID</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#204a87;font-weight:700>$(</span>aws sts get-caller-identity --query Account --output text<span style=color:#204a87;font-weight:700>)</span><span style=color:#4e9a06>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>TEMPOUT</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#204a87;font-weight:700>$(</span>mktemp<span style=color:#204a87;font-weight:700>)</span><span style=color:#4e9a06>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#204a87>export</span> <span style=color:#000>ALIAS_VERSION</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;</span><span style=color:#204a87;font-weight:700>$(</span>aws ssm get-parameter --name <span style=color:#4e9a06>&#34;/aws/service/eks/optimized-ami/</span><span style=color:#4e9a06>${</span><span style=color:#000>K8S_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>/amazon-linux-2023/x86_64/standard/recommended/image_id&#34;</span> --query Parameter.Value <span style=color:#000;font-weight:700>|</span> xargs aws ec2 describe-images --query <span style=color:#4e9a06>&#39;Images[0].Name&#39;</span> --image-ids <span style=color:#000;font-weight:700>|</span> sed -r <span style=color:#4e9a06>&#39;s/^.*(v[[:digit:]]+).*$/\1/&#39;</span><span style=color:#204a87;font-weight:700>)</span><span style=color:#4e9a06>&#34;</span>
</span></span></code></pre></div><p>If you open a new shell to run steps in this procedure, you need to set some or all of the environment variables again. To remind yourself of these values, type:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#204a87>echo</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_NAMESPACE</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>K8S_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>AWS_DEFAULT_REGION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>AWS_ACCOUNT_ID</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>TEMPOUT</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>ALIAS_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span>
</span></span></code></pre></div><h3 id=create-a-cluster-and-add-karpenter>Create a cluster and add Karpenter</h3><p>Please refer to the <a href=https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html>Getting Started with Karpenter</a> to create a cluster and add Karpenter.</p><h3 id=install-the-gpu-operator>Install the gpu operator</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>helm repo add nvidia https://helm.ngc.nvidia.com/nvidia <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    <span style=color:#ce5c00;font-weight:700>&amp;&amp;</span> helm repo update
</span></span><span style=display:flex><span>helm install --wait --generate-name <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    -n gpu-operator --create-namespace <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    nvidia/gpu-operator <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    --version<span style=color:#ce5c00;font-weight:700>=</span>v25.3.0
</span></span></code></pre></div><h3 id=install-llmaz-with-inftyai-scheduler-enabled>Install llmaz with InftyAI scheduler enabled</h3><p>Please refer to <a href=/docs/features/heterogeneous-cluster-support/>heterogeneous cluster support</a>.</p><h3 id=configure-karpenter-with-customized-image>Configure Karpenter with customized image</h3><p>We need to assign the <code>karpenter-core-llmaz</code> cluster role to the <code>karpenter</code> service account and update the karpenter image to the customized one.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#4e9a06>&lt;&lt;EOF | envsubst | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: rbac.authorization.k8s.io/v1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: ClusterRoleBinding
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter-core-llmaz
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>roleRef:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  apiGroup: rbac.authorization.k8s.io
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  kind: ClusterRole
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter-core-llmaz
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>subjects:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>- kind: ServiceAccount
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  namespace: ${KARPENTER_NAMESPACE}
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>---
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: rbac.authorization.k8s.io/v1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: ClusterRole
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: karpenter-core-llmaz
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>rules:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>- apiGroups: [&#34;llmaz.io&#34;]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  resources: [&#34;openmodels&#34;]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  verbs: [&#34;get&#34;, &#34;list&#34;, &#34;watch&#34;]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter --version <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> --namespace <span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_NAMESPACE</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> --create-namespace <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set <span style=color:#4e9a06>&#34;settings.clusterName=</span><span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set <span style=color:#4e9a06>&#34;settings.interruptionQueue=</span><span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.requests.cpu<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.requests.memory<span style=color:#ce5c00;font-weight:700>=</span>1Gi <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.limits.cpu<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.resources.limits.memory<span style=color:#ce5c00;font-weight:700>=</span>1Gi <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --wait <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.image.repository<span style=color:#ce5c00;font-weight:700>=</span>inftyai/karpenter-provider-aws <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set <span style=color:#4e9a06>&#34;controller.image.tag=</span><span style=color:#4e9a06>${</span><span style=color:#000>KARPENTER_VERSION</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  --set controller.image.digest<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;&#34;</span>
</span></span></code></pre></div><h2 id=basic-example>Basic Example</h2><ol><li>Create a gpu node pool</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#4e9a06>&lt;&lt;EOF | envsubst | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: karpenter.k8s.aws/v1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: E</span>C2NodeClass
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: llmaz-demo            <span style=color:#8f5902;font-style:italic># you can change the name to a more meaningful one, please align with the node pool&#39;s nodeClassRef.</span>
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  amiSelectorTerms:
</span></span><span style=display:flex><span>  - alias: al2023@<span style=color:#4e9a06>${</span><span style=color:#000>ALIAS_VERSION</span><span style=color:#4e9a06>}</span>
</span></span><span style=display:flex><span>  blockDeviceMappings:
</span></span><span style=display:flex><span>  <span style=color:#8f5902;font-style:italic># the default volume size of the selected AMI is 20Gi, it is not enough for kubelet to pull</span>
</span></span><span style=display:flex><span>  <span style=color:#8f5902;font-style:italic># the images and run the workloads. So we need to map a larger volume to the root device. </span>
</span></span><span style=display:flex><span>  <span style=color:#8f5902;font-style:italic># You can change the volume size to a larger value according to your actual needs.</span>
</span></span><span style=display:flex><span>  - deviceName: /dev/xvda
</span></span><span style=display:flex><span>    ebs:
</span></span><span style=display:flex><span>      deleteOnTermination: <span style=color:#204a87>true</span>
</span></span><span style=display:flex><span>      volumeSize: 50Gi     
</span></span><span style=display:flex><span>      volumeType: gp3
</span></span><span style=display:flex><span>  role: KarpenterNodeRole-<span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span>          <span style=color:#8f5902;font-style:italic># replace with your cluster name</span>
</span></span><span style=display:flex><span>  securityGroupSelectorTerms:
</span></span><span style=display:flex><span>  - tags:
</span></span><span style=display:flex><span>      karpenter.sh/discovery: <span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span>      <span style=color:#8f5902;font-style:italic># replace with your cluster name</span>
</span></span><span style=display:flex><span>  subnetSelectorTerms:
</span></span><span style=display:flex><span>  - tags:
</span></span><span style=display:flex><span>      karpenter.sh/discovery: <span style=color:#4e9a06>${</span><span style=color:#000>CLUSTER_NAME</span><span style=color:#4e9a06>}</span>      <span style=color:#8f5902;font-style:italic># replace with your cluster name</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: karpenter.sh/v1
</span></span><span style=display:flex><span>kind: NodePool
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: llmaz-demo-gpu-nodepool  <span style=color:#8f5902;font-style:italic># you can change the name to a more meaningful one. </span>
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  disruption:
</span></span><span style=display:flex><span>    budgets:
</span></span><span style=display:flex><span>    - nodes: 10%
</span></span><span style=display:flex><span>    consolidateAfter: 5m        
</span></span><span style=display:flex><span>    consolidationPolicy: WhenEmptyOrUnderutilized
</span></span><span style=display:flex><span>  limits:  <span style=color:#8f5902;font-style:italic># You can change the limits to match your actual needs.</span>
</span></span><span style=display:flex><span>    cpu: <span style=color:#0000cf;font-weight:700>1000</span>
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      expireAfter: 720h
</span></span><span style=display:flex><span>      nodeClassRef:
</span></span><span style=display:flex><span>        group: karpenter.k8s.aws
</span></span><span style=display:flex><span>        kind: EC2NodeClass
</span></span><span style=display:flex><span>        name: llmaz-demo
</span></span><span style=display:flex><span>      requirements:
</span></span><span style=display:flex><span>      - key: kubernetes.io/arch
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:
</span></span><span style=display:flex><span>        - amd64
</span></span><span style=display:flex><span>      - key: kubernetes.io/os
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:
</span></span><span style=display:flex><span>        - linux
</span></span><span style=display:flex><span>      - key: karpenter.sh/capacity-type
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:
</span></span><span style=display:flex><span>        - spot
</span></span><span style=display:flex><span>      - key: karpenter.k8s.aws/instance-family
</span></span><span style=display:flex><span>        operator: In
</span></span><span style=display:flex><span>        values:                                <span style=color:#8f5902;font-style:italic># replace with your instance-family with gpu supported</span>
</span></span><span style=display:flex><span>        - g4dn
</span></span><span style=display:flex><span>        - g5g
</span></span><span style=display:flex><span>      taints:
</span></span><span style=display:flex><span>      - effect: NoSchedule
</span></span><span style=display:flex><span>        key: nvidia.com/gpu
</span></span><span style=display:flex><span>        value: <span style=color:#4e9a06>&#34;true&#34;</span>
</span></span></code></pre></div><ol start=2><li>Deploy a model with flavors</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#4e9a06>&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: llmaz.io/v1alpha1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: OpenModel
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>spec:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  familyName: qwen2
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  source:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    modelHub:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      modelID: Qwen/Qwen2-0.5B-Instruct
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  inferenceConfig:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    flavors:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # The g5g instance family in the aws cloud can provide the t4g GPU type.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # we define the instance family in the node pool like llmaz-demo-gpu-nodepool.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      - name: t4g
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        limits:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          nvidia.com/gpu: 1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The flavorName is not recongnized by the Karpenter, so we need to specify the
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # instance-gpu-name via nodeSelector to match the t4g GPU type when node is provisioned
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # by Karpenter from multiple node pools.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # When you only have a single node pool to provision the GPU instance and the node pool
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # only has one GPU type, it is okay to not specify the nodeSelector. But in practice,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # it is better to specify the nodeSelector to make the provisioned node more predictable.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The available node labels for selecting the target GPU device is listed below:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-count
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-manufacturer
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-memory
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-name
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        nodeSelector:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          karpenter.k8s.aws/instance-gpu-name: t4g
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # The g4dn instance family in the aws cloud can provide the t4 GPU type.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      # we define the instance family in the node pool like llmaz-demo-gpu-nodepool.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      - name: t4
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        limits:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          nvidia.com/gpu: 1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The flavorName is not recongnized by the Karpenter, so we need to specify the
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # instance-gpu-name via nodeSelector to match the t4 GPU type when node is provisioned
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # by Karpenter from multiple node pools.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # When you only have a single node pool to provision the GPU instance and the node pool
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # only has one GPU type, it is okay to not specify the nodeSelector. But in practice,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # it is better to specify the nodeSelector to make the provisioned node more predictable.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        #
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # The available node labels for selecting the target GPU device is listed below:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-count
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-manufacturer
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-memory
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        # karpenter.k8s.aws/instance-gpu-name
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        nodeSelector:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>          karpenter.k8s.aws/instance-gpu-name: t4
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>---
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># Currently, the Playground resource type does not support to configure tolerations
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># for the generated pods. But luckily, when a pod with the `nvidia.com/gpu` resource  
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># is created on the eks cluster, the generated pod will be tweaked with the following
</span></span></span><span style=display:flex><span><span style=color:#4e9a06># tolerations:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#   - effect: NoExecute
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#      key: node.kubernetes.io/not-ready
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#      operator: Exists
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#      tolerationSeconds: 300
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#   - effect: NoExecute
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     key: node.kubernetes.io/unreachable
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     operator: Exists
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     tolerationSeconds: 300
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#   - effect: NoSchedule
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     key: nvidia.com/gpu
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>#     operator: Exists
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>apiVersion: inference.llmaz.io/v1alpha1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>kind: Playground
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>metadata:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  labels:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    llmaz.io/model-name: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  name: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>spec:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  backendRuntimeConfig:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    backendName: tgi
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    # Due to the limitation of our aws account, we have to decrease the resources to match
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    # the avaliable instance type which is g4dn.xlarge. If your account has no such limitation,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    # you can remove the custom resources settings below.
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    resources:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      limits:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        cpu: &#34;2&#34;
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        memory: 4Gi
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>      requests:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        cpu: &#34;2&#34;
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        memory: 4Gi
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  modelClaim:
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    modelName: qwen2-0--5b
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>  replicas: 1
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>EOF</span>
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-f489e01e2e14261978166c1d55f39718>3 - Open-WebUI</h1><p><a href=https://github.com/open-webui/open-webui>Open WebUI</a> is a user-friendly AI interface with OpenAI-compatible APIs, serving as the default chatbot for llmaz.</p><h2 id=prerequisites>Prerequisites</h2><ul><li>Make sure <a href=https://github.com/envoyproxy/gateway>EnvoyGateway</a> and <a href=https://github.com/envoyproxy/ai-gateway>Envoy AI Gateway</a> are installed, both of them are installed by default in llmaz. See <a href=docs/envoy-ai-gateway.md>AI Gateway</a> for more details.</li></ul><h2 id=how-to-use>How to use</h2><h3 id=enable-open-webui>Enable Open WebUI</h3><p>Open-WebUI is enabled by default in the <code>values.global.yaml</code> and will be deployed in llmaz-system.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>open-webui</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><h3 id=set-the-service-address>Set the Service Address</h3><ol><li><p>Run <code>kubectl get svc -n llmaz-system</code> to list out the services, the output looks like below, the LoadBalancer service name will be used later.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cmd data-lang=cmd><span style=display:flex><span>envoy-default-default-envoy-ai-gateway-dbec795a   LoadBalancer   10.96.145.150   <span style=color:#000;font-weight:700>&lt;</span>pending<span style=color:#000;font-weight:700>&gt;</span>     80:30548/TCP                              132m
</span></span><span style=display:flex><span>envoy-gateway                                     ClusterIP      10.96.52.76     <span style=color:#000;font-weight:700>&lt;</span>none<span style=color:#000;font-weight:700>&gt;</span>        18000/TCP,18001/TCP,18002/TCP,19001/TCP   172m
</span></span></code></pre></div></li><li><p>Port forward the Open-WebUI service, and visit <code>http://localhost:8080</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl port-forward svc/open-webui 8080:80 -n llmaz-system
</span></span></code></pre></div></li><li><p>Click <code>Settings -> Admin Settings -> Connections</code>, set the URL to <code>http://envoy-default-default-envoy-ai-gateway-dbec795a.llmaz-system.svc.cluster.local/v1</code> and save. (You can also set the <code>openaiBaseApiUrl</code> in the <code>values.global.yaml</code>)</p></li></ol><p><img alt=img src=/images/open-webui-setting.png></p><ol start=4><li>Start to chat now.</li></ol><h2 id=persistence>Persistence</h2><p>Set the <code>persistence=true</code> in <code>values.global.yaml</code> to enable persistence.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7d3a7a2ca4bbfe3c7b0f023d3eac77c6>4 - Prometheus Operator</h1><p>This document provides deployment steps to install and configure Prometheus Operator in a Kubernetes cluster.</p><h3 id=install-the-prometheus-operator>Install the prometheus operator</h3><p>Please follow the <a href=https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/getting-started/installation.md>documentation</a> to install prometheus operator or simply run the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -sL https://github.com/prometheus-operator/prometheus-operator/releases/download/v0.81.0/bundle.yaml <span style=color:#000;font-weight:700>|</span> kubectl create -f -
</span></span></code></pre></div><p>Ensure that the Prometheus Operator Pod is running successfully.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Installing the prometheus operator</span>
</span></span><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu# kubectl get pods
</span></span><span style=display:flex><span>NAME                                   READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>prometheus-operator-55b5c96cf8-jl2nx   1/1     Running   <span style=color:#0000cf;font-weight:700>0</span>          12s
</span></span></code></pre></div><h3 id=install-the-servicemonitor-cr-for-llmaz>Install the ServiceMonitor CR for llmaz</h3><p>To enable monitoring for the llmaz system, you need to install the ServiceMonitor custom resource (CR).
You can either modify the Helm chart prometheus according to the <a href=https://github.com/InftyAI/llmaz/blob/main/chart/values.global.yaml>documentation</a> or use <code>make install-prometheus</code> in Makefile.</p><ul><li>Using Helm Chart: to modify the values.global.yaml</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>prometheus</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#8f5902;font-style:italic># -- Whether to enable Prometheus metrics exporting.</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>enable</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><ul><li>Using Makefile Command: <code>make install-prometheus</code></li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# make install-prometheus
</span></span><span style=display:flex><span>kubectl apply --server-side -k config/prometheus
</span></span><span style=display:flex><span>serviceaccount/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>clusterrole.rbac.authorization.k8s.io/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>clusterrolebinding.rbac.authorization.k8s.io/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>prometheus.monitoring.coreos.com/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>servicemonitor.monitoring.coreos.com/llmaz-controller-manager-metrics-monitor serverside-applied
</span></span></code></pre></div><h3 id=check-related-resources>Check Related Resources</h3><p>Verify that the necessary resources have been created:</p><ul><li>ServiceMonitor</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# kubectl get ServiceMonitor -n llmaz-system
</span></span><span style=display:flex><span>NAME                                       AGE
</span></span><span style=display:flex><span>llmaz-controller-manager-metrics-monitor   59s
</span></span></code></pre></div><ul><li>Prometheus Pods</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# kubectl get pods -n llmaz-system
</span></span><span style=display:flex><span>NAME                                        READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>llmaz-controller-manager-7ff8f7d9bd-vztls   2/2     Running   <span style=color:#0000cf;font-weight:700>0</span>          28s
</span></span><span style=display:flex><span>prometheus-llmaz-prometheus-0               2/2     Running   <span style=color:#0000cf;font-weight:700>0</span>          27s
</span></span></code></pre></div><ul><li>Services</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# kubectl get svc -n llmaz-system
</span></span><span style=display:flex><span>NAME                                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#ce5c00;font-weight:700>(</span>S<span style=color:#ce5c00;font-weight:700>)</span>    AGE
</span></span><span style=display:flex><span>llmaz-controller-manager-metrics-service   ClusterIP   10.96.79.226    &lt;none&gt;        8443/TCP   46s
</span></span><span style=display:flex><span>llmaz-webhook-service                      ClusterIP   10.96.249.226   &lt;none&gt;        443/TCP    46s
</span></span><span style=display:flex><span>prometheus-operated                        ClusterIP   None            &lt;none&gt;        9090/TCP   45s
</span></span></code></pre></div><h3 id=view-metrics-using-the-prometheus-ui>View metrics using the prometheus UI</h3><p>Use port forwarding to access the Prometheus UI from your local machine:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu# kubectl port-forward services/prometheus-operated 9090:9090 --address 0.0.0.0 -n llmaz-system
</span></span><span style=display:flex><span>Forwarding from 0.0.0.0:9090 -&gt; <span style=color:#0000cf;font-weight:700>9090</span>
</span></span></code></pre></div><p>If using kind, we can use port-forward, <code>kubectl port-forward services/prometheus-operated 39090:9090 --address 0.0.0.0 -n llmaz-system</code>
This allows us to access prometheus using a browser: <code>http://localhost:9090/query</code></p><p><img alt=prometheus src="/images/prometheus.png?raw=true"></p></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title aria-label><a target=_blank rel=noopener href aria-label><i></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/InftyAI/llmaz aria-label=GitHub><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=X aria-label=X><a target=_blank rel=noopener href=https://x.com/InftyAI aria-label=X><i class="fab fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Slack aria-label=Slack><a target=_blank rel=noopener href=https://inftyai.slack.com/ aria-label=Slack><i class="fab fa-slack"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2025
<span class=td-footer__authors>The InftyAI Team</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.69e2c1ae9320465ab10236d9ef752c6a4442c54b48b883b17c497b7c7d96a796.js integrity="sha256-aeLBrpMgRlqxAjbZ73UsakRCxUtIuIOxfEl7fH2Wp5Y=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>