<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://llmaz.inftyai.com/docs/integrations/><link rel=alternate type=application/rss+xml href=https://llmaz.inftyai.com/docs/integrations/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Integrations | llmaz</title>
<meta name=description content="This section contains the llmaz integration information."><meta property="og:url" content="https://llmaz.inftyai.com/docs/integrations/"><meta property="og:site_name" content="llmaz"><meta property="og:title" content="Integrations"><meta property="og:description" content="This section contains the llmaz integration information."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Integrations"><meta itemprop=description content="This section contains the llmaz integration information."><meta itemprop=dateModified content="2025-05-20T10:41:25+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Integrations"><meta name=twitter:description content="This section contains the llmaz integration information."><link rel=preload href=/scss/main.min.df756438a7e020f7456327e32660cfd018c35e49c250d72b637e5a0fdc7f595c.css as=style integrity="sha256-33VkOKfgIPdFYyfjJmDP0BjDXknCUNcrY35aD9x/WVw=" crossorigin=anonymous><link href=/scss/main.min.df756438a7e020f7456327e32660cfd018c35e49c250d72b637e5a0fdc7f595c.css rel=stylesheet integrity="sha256-33VkOKfgIPdFYyfjJmDP0BjDXknCUNcrY35aD9x/WVw=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg version="1.2" viewBox="0 0 29 30" width="29" height="30"><style>.a{fill:#fff;stroke:#e94751;stroke-linecap:round;stroke-linejoin:round;stroke-width:.4}</style><path class="a" d="m14.3.0-13.7 6.5c-.2.0-.2.3.0.4L3 8.1q.2.1.4.0l11-5.5q.2.0.3.0l1.9.9c.3.2.2.3.0.4L6 9.3c-.2.1-.2.3.0.4L8.5 11q.1.1.3.0l10.8-6q.1.0.2.0l2.5 1.2c.2.0.2.3.0.4l-10.1 5.5c-.4.1-.6.5-.2.8l2.3 1.2c.2.1.4.0.5.0L28.2 7c.4-.2.4-.7.0-.9L14.7.0q-.2.0-.4.0z"/><path class="a" d="m29 8.8v3.3l-.1.1-9.3 12.5 9.1-4.9c.1.0.3.0.3.2v3l-13.2 7c-.2.1-.6-.1-.6-.4v-3.5q0-.1.1-.1l9.3-12.2s0-.1-.1.0l-9 5.4c-.1.1-.3.0-.3-.2v-3c0-.3.2-.5.4-.6l12.9-6.9c.2-.1.5.0.5.3z"/><path class="a" d="m13.6 15.4-12.9-6.6c-.3-.2-.7.1-.7.4v13.3q0 .1.1.2l2.1 1c.2.1.5-.1.5-.4v-3.2l7.5 3.8v4.3q0 .2.2.3l2.7 1.5c.3.1.7-.1.7-.5V15.9c0-.2-.1-.4-.2-.5zM2.7 17.3v-3.4c0-.1.2-.2.3-.1l7 3.4c.1.1.2.3.2.5V21z"/></svg></span><span class=navbar-brand__name>llmaz</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class="nav-link active" href=/docs/><span>Documentation</span></a></li><li class=nav-item><a class=nav-link href=/docs/reference/><span>Reference</span></a></li><li class=nav-item><a class=nav-link href=/blog/><span>Blog</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><ul class=dropdown-menu><li><a class=dropdown-item href=/docs>latest</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.11a63b6db4ab3d6d015e84572b102665.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/integrations/>Return to the regular view of this page</a>.</p></div><h1 class=title>Integrations</h1><div class=lead>This section contains the llmaz integration information.</div><ul><li>1: <a href=#pg-4883ef24b3c01ce986dd46f3062ba8ef>Envoy AI Gateway</a></li><li>2: <a href=#pg-f489e01e2e14261978166c1d55f39718>Open-WebUI</a></li><li>3: <a href=#pg-7d3a7a2ca4bbfe3c7b0f023d3eac77c6>Prometheus Operator</a></li><li>4: <a href=#pg-7b38a55cdf7f3c862f4b985f4bac4241>Supported Inference Backends</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-4883ef24b3c01ce986dd46f3062ba8ef>1 - Envoy AI Gateway</h1><p><a href=https://aigateway.envoyproxy.io/>Envoy AI Gateway</a> is an open source project for using Envoy Gateway
to handle request traffic from application clients to Generative AI services.</p><h2 id=how-to-use>How to use</h2><h3 id=enable-envoy-gateway-and-envoy-ai-gateway>Enable Envoy Gateway and Envoy AI Gateway</h3><p>Both of them are already enabled by default in <code>values.global.yaml</code> and will be deployed in llmaz-system.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>envoy-gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>envoy-ai-gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>However, <a href=https://gateway.envoyproxy.io/latest/install/install-helm/>Envoy Gateway</a> and <a href=https://aigateway.envoyproxy.io/docs/getting-started/>Envoy AI Gateway</a> can be deployed standalone in case you want to deploy them in other namespaces.</p><h3 id=basic-example>Basic Example</h3><p>To expose your models via Envoy Gateway, you need to create a GatewayClass, Gateway, and AIGatewayRoute. The following example shows how to do this.</p><p>We&rsquo;ll deploy two models <code>Qwen/Qwen2-0.5B-Instruct-GGUF</code> and <code>Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF</code> with llama.cpp (cpu only) and expose them via Envoy AI Gateway.</p><p>The full example is <a href=https://github.com/InftyAI/llmaz/blob/main/docs/examples/envoy-ai-gateway/basic.yaml>here</a>, apply it.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/InftyAI/llmaz/refs/heads/main/docs/examples/envoy-ai-gateway/basic.yaml
</span></span></code></pre></div><h3 id=query-ai-gateway-apis>Query AI Gateway APIs</h3><p>If Open-WebUI is enabled, you can chat via the webui (recommended), see <a href=/docs/integrations/open-webui/>documentation</a>. Otherwise, following the steps below to test the Envoy AI Gateway APIs.</p><p>I. Port-forwarding the <code>LoadBalancer</code> service in llmaz-system, like:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl -n llmaz-system port-forward <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  <span style=color:#204a87;font-weight:700>$(</span>kubectl -n llmaz-system get svc <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    -l gateway.envoyproxy.io/owning-gateway-name<span style=color:#ce5c00;font-weight:700>=</span>default-envoy-ai-gateway <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>    -o name<span style=color:#204a87;font-weight:700>)</span> <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>  8080:80
</span></span></code></pre></div><p>II. Query <code>curl http://localhost:8080/v1/models | jq .</code>, available models will be listed. Expected response will look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;data&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>[</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;id&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;qwen2-0.5b&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;created&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1745327294</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;model&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;owned_by&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;Envoy AI Gateway&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>},</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;id&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;qwen2.5-coder&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;created&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1745327294</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;model&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;owned_by&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;Envoy AI Gateway&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>],</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;list&#34;</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>}</span>
</span></span></code></pre></div><p>III. Query <code>http://localhost:8080/v1/chat/completions</code> to chat with the model. Here, we ask the <code>qwen2-0.5b</code> model, the query will look like:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -H <span style=color:#4e9a06>&#34;Content-Type: application/json&#34;</span>     -d <span style=color:#4e9a06>&#39;{
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        &#34;model&#34;: &#34;qwen2-0.5b&#34;,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        &#34;messages&#34;: [
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>            {
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>                &#34;role&#34;: &#34;system&#34;,
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>                &#34;content&#34;: &#34;Hi.&#34;
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>            }
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>        ]
</span></span></span><span style=display:flex><span><span style=color:#4e9a06>    }&#39;</span>     http://localhost:8080/v1/chat/completions <span style=color:#000;font-weight:700>|</span> jq .
</span></span></code></pre></div><p>Expected response will look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;choices&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>[</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;finish_reason&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;stop&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;index&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>0</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&#34;message&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&#34;role&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;assistant&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&#34;content&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;Hello! How can I assist you today?&#34;</span>
</span></span><span style=display:flex><span>      <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>],</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;created&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1745327371</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;model&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;qwen2-0.5b&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;system_fingerprint&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;b5124-bc091a4d&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;object&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;chat.completion&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;usage&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;completion_tokens&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>10</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_tokens&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>10</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;total_tokens&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>20</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>},</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;id&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;chatcmpl-AODlT8xnf4OjJwpQH31XD4yehHLnurr0&#34;</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&#34;timings&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_n&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>319.876</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_per_token_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>319.876</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;prompt_per_second&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>3.1262114069201816</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_n&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>10</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>1309.393</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_per_token_ms&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>130.9393</span><span style=color:#000;font-weight:700>,</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&#34;predicted_per_second&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#0000cf;font-weight:700>7.63712651587415</span>
</span></span><span style=display:flex><span>  <span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>}</span>
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-f489e01e2e14261978166c1d55f39718>2 - Open-WebUI</h1><p><a href=https://github.com/open-webui/open-webui>Open WebUI</a> is a user-friendly AI interface with OpenAI-compatible APIs, serving as the default chatbot for llmaz.</p><h2 id=prerequisites>Prerequisites</h2><ul><li>Make sure <a href=https://github.com/envoyproxy/gateway>EnvoyGateway</a> and <a href=https://github.com/envoyproxy/ai-gateway>Envoy AI Gateway</a> are installed, both of them are installed by default in llmaz. See <a href=docs/envoy-ai-gateway.md>AI Gateway</a> for more details.</li></ul><h2 id=how-to-use>How to use</h2><h3 id=enable-open-webui>Enable Open WebUI</h3><p>Open-WebUI is enabled by default in the <code>values.global.yaml</code> and will be deployed in llmaz-system.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>open-webui</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><h3 id=set-the-service-address>Set the Service Address</h3><ol><li><p>Run <code>kubectl get svc -n llmaz-system</code> to list out the services, the output looks like below, the LoadBalancer service name will be used later.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cmd data-lang=cmd><span style=display:flex><span>envoy-default-default-envoy-ai-gateway-dbec795a   LoadBalancer   10.96.145.150   <span style=color:#000;font-weight:700>&lt;</span>pending<span style=color:#000;font-weight:700>&gt;</span>     80:30548/TCP                              132m
</span></span><span style=display:flex><span>envoy-gateway                                     ClusterIP      10.96.52.76     <span style=color:#000;font-weight:700>&lt;</span>none<span style=color:#000;font-weight:700>&gt;</span>        18000/TCP,18001/TCP,18002/TCP,19001/TCP   172m
</span></span></code></pre></div></li><li><p>Port forward the Open-WebUI service, and visit <code>http://localhost:8080</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl port-forward svc/open-webui 8080:80 -n llmaz-system
</span></span></code></pre></div></li><li><p>Click <code>Settings -> Admin Settings -> Connections</code>, set the URL to <code>http://envoy-default-default-envoy-ai-gateway-dbec795a.llmaz-system.svc.cluster.local/v1</code> and save. (You can also set the <code>openaiBaseApiUrl</code> in the <code>values.global.yaml</code>)</p></li></ol><p><img alt=img src=/images/open-webui-setting.png></p><ol start=4><li>Start to chat now.</li></ol><h2 id=persistence>Persistence</h2><p>Set the <code>persistence=true</code> in <code>values.global.yaml</code> to enable persistence.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7d3a7a2ca4bbfe3c7b0f023d3eac77c6>3 - Prometheus Operator</h1><p>This document provides deployment steps to install and configure Prometheus Operator in a Kubernetes cluster.</p><h3 id=install-the-prometheus-operator>Install the prometheus operator</h3><p>Please follow the <a href=https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/getting-started/installation.md>documentation</a> to install prometheus operator or simply run the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -sL https://github.com/prometheus-operator/prometheus-operator/releases/download/v0.81.0/bundle.yaml <span style=color:#000;font-weight:700>|</span> kubectl delete -f -
</span></span></code></pre></div><p>Ensure that the Prometheus Operator Pod is running successfully.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Installing the prometheus operator</span>
</span></span><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu# kubectl get pods
</span></span><span style=display:flex><span>NAME                                   READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>prometheus-operator-55b5c96cf8-jl2nx   1/1     Running   <span style=color:#0000cf;font-weight:700>0</span>          12s
</span></span></code></pre></div><h3 id=install-the-servicemonitor-cr-for-llmaz>Install the ServiceMonitor CR for llmaz</h3><p>To enable monitoring for the llmaz system, you need to install the ServiceMonitor custom resource (CR).
You can either modify the Helm chart prometheus according to the <a href=https://github.com/InftyAI/llmaz/blob/main/chart/values.global.yaml>documentation</a> or use <code>make install-prometheus</code> in Makefile.</p><ul><li>Using Helm Chart: to modify the values.global.yaml</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>prometheus</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#8f5902;font-style:italic># -- Whether to enable Prometheus metrics exporting.</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>enable</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><ul><li>Using Makefile Command: <code>make install-prometheus</code></li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# make install-prometheus
</span></span><span style=display:flex><span>kubectl apply --server-side -k config/prometheus
</span></span><span style=display:flex><span>serviceaccount/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>clusterrole.rbac.authorization.k8s.io/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>clusterrolebinding.rbac.authorization.k8s.io/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>prometheus.monitoring.coreos.com/llmaz-prometheus serverside-applied
</span></span><span style=display:flex><span>servicemonitor.monitoring.coreos.com/llmaz-controller-manager-metrics-monitor serverside-applied
</span></span></code></pre></div><h3 id=check-related-resources>Check Related Resources</h3><p>Verify that the necessary resources have been created:</p><ul><li>ServiceMonitor</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# kubectl get ServiceMonitor -n llmaz-system
</span></span><span style=display:flex><span>NAME                                       AGE
</span></span><span style=display:flex><span>llmaz-controller-manager-metrics-monitor   59s
</span></span></code></pre></div><ul><li>Prometheus Pods</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# kubectl get pods -n llmaz-system
</span></span><span style=display:flex><span>NAME                                        READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>llmaz-controller-manager-7ff8f7d9bd-vztls   2/2     Running   <span style=color:#0000cf;font-weight:700>0</span>          28s
</span></span><span style=display:flex><span>prometheus-llmaz-prometheus-0               2/2     Running   <span style=color:#0000cf;font-weight:700>0</span>          27s
</span></span></code></pre></div><ul><li>Services</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu/llmaz# kubectl get svc -n llmaz-system
</span></span><span style=display:flex><span>NAME                                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#ce5c00;font-weight:700>(</span>S<span style=color:#ce5c00;font-weight:700>)</span>    AGE
</span></span><span style=display:flex><span>llmaz-controller-manager-metrics-service   ClusterIP   10.96.79.226    &lt;none&gt;        8443/TCP   46s
</span></span><span style=display:flex><span>llmaz-webhook-service                      ClusterIP   10.96.249.226   &lt;none&gt;        443/TCP    46s
</span></span><span style=display:flex><span>prometheus-operated                        ClusterIP   None            &lt;none&gt;        9090/TCP   45s
</span></span></code></pre></div><h3 id=view-metrics-using-the-prometheus-ui>View metrics using the prometheus UI</h3><p>Use port forwarding to access the Prometheus UI from your local machine:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>root@VM-0-5-ubuntu:/home/ubuntu# kubectl port-forward services/prometheus-operated 9090:9090 --address 0.0.0.0 -n llmaz-system
</span></span><span style=display:flex><span>Forwarding from 0.0.0.0:9090 -&gt; <span style=color:#0000cf;font-weight:700>9090</span>
</span></span></code></pre></div><p>If using kind, we can use port-forward, <code>kubectl port-forward services/prometheus-operated 39090:9090 --address 0.0.0.0 -n llmaz-system</code>
This allows us to access prometheus using a browser: <code>http://localhost:9090/query</code></p><p><img alt=prometheus src="/images/prometheus.png?raw=true"></p></div><div class=td-content style=page-break-before:always><h1 id=pg-7b38a55cdf7f3c862f4b985f4bac4241>4 - Supported Inference Backends</h1><p>If you want to integrate more backends into llmaz, please refer to this <a href=https://github.com/InftyAI/llmaz/pull/182>PR</a>. It&rsquo;s always welcomed.</p><h2 id=llamacpp>llama.cpp</h2><p><a href=https://github.com/ggerganov/llama.cpp>llama.cpp</a> is to enable LLM inference with minimal setup and state-of-the-art performance on a wide variety of hardware - locally and in the cloud.</p><h2 id=sglang>SGLang</h2><p><a href=https://github.com/sgl-project/sglang>SGLang</a> is yet another fast serving framework for large language models and vision language models.</p><h2 id=tensorrt-llm>TensorRT-LLM</h2><p><a href=https://github.com/NVIDIA/TensorRT-LLM>TensorRT-LLM</a> provides users with an easy-to-use Python API to define Large Language Models (LLMs) and support state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that orchestrate the inference execution in performant way.</p><h2 id=text-generation-inference>Text-Generation-Inference</h2><p><a href=https://github.com/huggingface/text-generation-inference>text-generation-inference</a> is a Rust, Python and gRPC server for text generation inference. Used in production at Hugging Face to power Hugging Chat, the Inference API and Inference Endpoint.</p><h2 id=ollama>ollama</h2><p><a href=https://github.com/ollama/ollama>ollama</a> is running with Llama 3.2, Mistral, Gemma 2, and other large language models, based on llama.cpp, aims for local deploy.</p><h2 id=vllm>vLLM</h2><p><a href=https://github.com/vllm-project/vllm>vLLM</a> is a high-throughput and memory-efficient inference and serving engine for LLMs</p></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title aria-label><a target=_blank rel=noopener href aria-label><i></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/InftyAI/llmaz aria-label=GitHub><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=X aria-label=X><a target=_blank rel=noopener href=https://x.com/InftyAI aria-label=X><i class="fab fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Slack aria-label=Slack><a target=_blank rel=noopener href=https://inftyai.slack.com/ aria-label=Slack><i class="fab fa-slack"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2025
<span class=td-footer__authors>The InftyAI Team</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.69e2c1ae9320465ab10236d9ef752c6a4442c54b48b883b17c497b7c7d96a796.js integrity="sha256-aeLBrpMgRlqxAjbZ73UsakRCxUtIuIOxfEl7fH2Wp5Y=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>